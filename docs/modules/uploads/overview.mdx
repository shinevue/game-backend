---
title: "Uploads"
description: "Upload & store blobs of data."
sidebarTitle: Overview
---

| Source                                                                           | Name       | Status     | Database     |
| -------------------------------------------------------------------------------- | ---------- | ---------- | ------------ |
| [Source](https://github.com/rivet-gg/opengb-modules/tree/main/modules/uploads) | `uploads` | stable | Yes |

**Authors**

- [rivet-gg](https://github.com/rivet-gg)
- [Blckbrry-Pi](https://github.com/Blckbrry-Pi)
- [NathanFlurry](https://github.com/NathanFlurry)

**Dependencies**

_No dependencies_

## Installation

<Tabs>

<Tab title="CLI">

```sh CLI
opengb module add uploads
```

</Tab>

<Tab title="backend.json">

Add the following to your `backend.json`:

```json backend.json
"modules": {
	"uploads": {
		"config": {
			// Your config here. See below for more details.
		}
	}
}

```
</Tab>

</Tabs>

## Config

### Schema
		
```typescript
export interface Config {
  maxUploadSize?: string;
  maxMultipartUploadSize?: string;
  maxFilesPerUpload?: number;
  defaultMultipartChunkSize?: string;
}
```

### Default

```json
{}
```



## Scripts

### Public

<CardGroup>_No public scripts._</CardGroup>

### Internal

<CardGroup><Card title="Complete Upload" href="/modules/uploads/scripts/complete">Alert the module that the upload has been completed</Card><Card title="Delete Upload" href="/modules/uploads/scripts/delete">Removes the upload and deletes the files from the bucket</Card><Card title="Get File Link" href="/modules/uploads/scripts/get_public_file_urls">Get presigned download links for each of the specified files</Card><Card title="Get Upload Metadata" href="/modules/uploads/scripts/get">Get the metadata (including contained files) for specified upload IDs</Card><Card title="Prepare Upload" href="/modules/uploads/scripts/prepare">Prepare an upload batch for data transfer</Card></CardGroup>

## Errors

- **Combined Size Limit Exceeded** (`size_limit_exceeded`) There is a maximum total size per upload (see config)
- **Duplicate Paths Provided** (`duplicate_paths`) An upload cannot contain 2 files with the same paths (see `cause` for offending paths)
- **Multipart Upload Completion Failure** (`multipart_upload_completion_fail`) The multipart upload failed to complete (see `cause` for more information)
- **No Files Provided** (`no_files`) An upload must have at least 1 file
- **Possibility Of Too Many Chunks** (`too_many_chunks`) AWS S3 has a limit on the number of parts that can be uploaded in a
multipart upload. This limit is 10,000 parts. If the number of chunks
required to upload the maximum multipart upload size exceeds this limit,
any operation will preemptively throw this error.

- **S3 Not Configured** (`s3_not_configured`) The S3 bucket is not configured (missing env variables)
- **Too Many Files Provided** (`too_many_files`) There is a limit to how many files can be put into a single upload (see config)
- **Upload Already completed** (`upload_already_completed`) \`complete\` was already called on this upload
- **Upload Not Found** (`upload_not_found`) The provided upload ID didn't match any known existing uploads
